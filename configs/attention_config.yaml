# Multi-Head Attention Configuration
# Based on real-world communication and coordination constraints

attention:
  # Base attention parameters
  base:
    embed_dim: 256
    num_heads: 8
    dropout: 0.1
    use_bias: true
    batch_first: true
    
  # Hierarchical attention configuration
  hierarchical:
    enabled: true
    num_agents: 20
    cluster_size: 5
    num_clusters: 4
    communication_range: 100.0  # meters (based on WiFi/radio range)
    use_cross_level: true
    
    # Intra-cluster attention
    intra_cluster:
      num_heads: 4
      dropout: 0.1
      use_position_encoding: true
      
    # Inter-cluster attention  
    inter_cluster:
      num_heads: 4
      dropout: 0.1
      use_cluster_embedding: true
      
    # Cross-level attention
    cross_level:
      num_heads: 2
      dropout: 0.1
      
  # Physics-aware attention configuration
  physics_aware:
    enabled: true
    communication_range: 100.0      # meters
    min_safety_distance: 5.0        # meters (based on drone safety regulations)
    max_velocity: 20.0              # m/s (based on DJI Mavic 3 specs)
    energy_weight: 0.1              # Weight for energy efficiency
    collision_weight: 0.3           # Weight for collision avoidance
    
    # Real-world constraints
    constraints:
      max_acceleration: 10.0        # m/sÂ²
      battery_capacity: 5000.0      # mAh
      critical_battery_level: 0.2   # 20%
      comm_cost_per_meter: 0.001   # Watts per meter
      
  # Scalable attention configuration
  scalable:
    enabled: true
    max_agents: 50
    attention_types:
      - linear        # O(n) complexity
      - sparse        # O(n*k) complexity
      - local         # Windowed attention
      - efficient     # Memory-optimized
      
    # Linear attention
    linear:
      feature_dim: 64
      use_elu_feature_map: true
      
    # Sparse attention
    sparse:
      sparsity_ratio: 0.1    # Keep top 10% connections
      use_topk: true
      dynamic_sparsity: true
      
    # Local attention
    local:
      window_size: 5
      overlap: 1
      use_relative_position: true
      
    # Memory optimization
    memory:
      use_gradient_checkpointing: true
      use_mixed_precision: true
      chunk_size: 1000
      
  # Adaptive attention configuration
  adaptive:
    enabled: true
    num_heads_options: [4, 8, 16]
    scenario_types: ["simple", "moderate", "complex"]
    adaptation_rate: 0.1
    
    # Scenario classification
    classifier:
      use_complexity_score: true
      use_agent_density: true
      use_spatial_spread: true
      use_velocity_variance: true
      
    # Performance targets
    performance:
      target_latency_ms: 20.0      # Real-time constraint
      min_accuracy: 0.95
      max_memory_gb: 4.0
      
    # Adaptation triggers
    triggers:
      latency_threshold: 1.2        # 20% over target
      memory_threshold: 0.9         # 90% of max
      accuracy_threshold: 0.9       # 90% of target
      
# Visualization configuration
visualization:
  enabled: true
  figsize: [12, 8]
  colormap: "viridis"
  style: "whitegrid"
  
  # Animation settings
  animation:
    fps: 10
    duration: 30
    save_format: "gif"
    
  # Analysis settings
  analysis:
    detect_patterns: true
    pattern_types:
      - hub
      - clustering
      - uniform
      - sparse
    threshold: 0.1
    
# Training configuration
training:
  # Attention-specific training parameters
  attention_lr: 0.0001
  attention_weight_decay: 0.01
  warmup_steps: 1000
  
  # Regularization
  attention_dropout: 0.1
  attention_regularization: 0.001
  entropy_regularization: 0.01
  
  # Curriculum learning
  curriculum:
    start_agents: 5
    end_agents: 20
    increase_every: 1000  # steps
    
# Inference configuration
inference:
  # Real-time constraints
  max_batch_size: 100
  max_sequence_length: 50
  use_fp16: true
  
  # Caching
  cache_attention_weights: true
  cache_size: 1000
  
  # Fallback options
  fallback:
    enabled: true
    timeout_ms: 25
    simple_attention: true